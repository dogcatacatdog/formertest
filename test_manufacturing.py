import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.preprocessing import StandardScaler
from hybrid import InformerAutoformerHybrid, DynamicThreshold
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.offline as pyo
from ipywidgets import interact, widgets
import pickle
import os
import hashlib
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

def load_and_preprocess_data(csv_path, features=['TEMP', 'PRESSURE', 'RF_POWER'], target='CHAMBER_LOAD'):
    """ì œì¡°ì—… ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬"""
    df = pd.read_csv(csv_path)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.sort_values('timestamp').reset_index(drop=True)
    
    # í”¼ì²˜ ì„ íƒ
    feature_data = df[features].values
    target_data = df[target].values
    
    # ì •ê·œí™”
    feature_scaler = StandardScaler()
    target_scaler = StandardScaler()
    
    feature_scaled = feature_scaler.fit_transform(feature_data)
    target_scaled = target_scaler.fit_transform(target_data.reshape(-1, 1)).flatten()
    
    return feature_scaled, target_scaled, feature_scaler, target_scaler, df

def create_sequences(data, target, seq_len=96, pred_len=24):
    """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±"""
    X, y = [], []
    for i in range(len(data) - seq_len - pred_len + 1):
        X.append(data[i:i+seq_len])
        y.append(target[i+seq_len:i+seq_len+pred_len])
    return np.array(X), np.array(y)

def detect_anomalies_with_model(csv_path='sample_manufacturing.csv', use_interactive=True, use_cache=True, cache_dir='cache'):
    """í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ìƒ íƒì§€ (ìºì‹œ ì§€ì›)"""
    
    # 1. ë°ì´í„° ì—…ë°ì´íŠ¸ í™•ì¸
    data_updated, current_checksum = check_data_update(csv_path, cache_dir)
    
    print("=== ìºì‹œ ìƒíƒœ í™•ì¸ ===")
    print(f"ë°ì´í„° ì—…ë°ì´íŠ¸ ì—¬ë¶€: {'Yes' if data_updated else 'No'}")
    print(f"í˜„ì¬ ë°ì´í„° ì²´í¬ì„¬: {current_checksum[:10]}...")
    
    # 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    print("ë°ì´í„° ë¡œë“œ ì¤‘...")
    features, targets, feat_scaler, targ_scaler, df = load_and_preprocess_data(csv_path)
    
    # 3. ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
    seq_len = 96  # 8ì‹œê°„ (5ë¶„ ê°„ê²©)
    pred_len = 24 # 2ì‹œê°„ ì˜ˆì¸¡
    X, y = create_sequences(features, targets, seq_len, pred_len)
    
    print(f"ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ: X shape={X.shape}, y shape={y.shape}")
    
    # 4. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    # í…ì„œ ë³€í™˜
    X_train = torch.FloatTensor(X_train)
    y_train = torch.FloatTensor(y_train)
    X_test = torch.FloatTensor(X_test)
    y_test = torch.FloatTensor(y_test)
    
    # 5. ëª¨ë¸ ì„¤ì •
    model_config = {
        'input_dim': 3,
        'd_model': 64,
        'n_heads': 4,
        'd_ff': 128,
        'num_layers': 2,
        'out_len': pred_len,
        'use_patch': True,
        'patch_len': 12,
        'share_params': True
    }
    
    scaler_data = {
        'feat_scaler': feat_scaler,
        'targ_scaler': targ_scaler
    }
    
    train_losses = []
    model = None
    
    # 6. ìºì‹œ í™•ì¸ ë° ëª¨ë¸ ë¡œë“œ/í•™ìŠµ
    if use_cache and not data_updated:
        print("=== ìºì‹œì—ì„œ ëª¨ë¸ ë¡œë“œ ì‹œë„ ===")
        model, cache_data = load_model_cache(model_config, cache_dir)
        
        if model is not None and cache_data is not None:
            print("âœ“ ìºì‹œëœ ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
            # ìºì‹œëœ ìŠ¤ì¼€ì¼ëŸ¬ ì‚¬ìš©
            if 'scaler_data' in cache_data:
                cached_scalers = cache_data['scaler_data']
                feat_scaler = cached_scalers['feat_scaler']
                targ_scaler = cached_scalers['targ_scaler']
            
            # ìºì‹œëœ ë©”íƒ€ë°ì´í„°ì—ì„œ ì†ì‹¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            if 'train_losses' in cache_data.get('metadata', {}):
                train_losses = cache_data['metadata']['train_losses']
        else:
            print("âœ— ìºì‹œ ë¡œë“œ ì‹¤íŒ¨, ìƒˆë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")
    
    # 7. ëª¨ë¸ í•™ìŠµ (ìºì‹œê°€ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ëœ ê²½ìš°)
    if model is None:
        print("=== ìƒˆë¡œìš´ ëª¨ë¸ í•™ìŠµ ===")
        model = InformerAutoformerHybrid(**model_config)
        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
        criterion = nn.MSELoss()
        
        model.train()
        for epoch in range(10):
            epoch_loss = 0
            for i in range(0, len(X_train), 8):
                batch_x = X_train[i:i+8]
                batch_y = y_train[i:i+8]
                
                optimizer.zero_grad()
                output = model(batch_x, batch_y)
                loss = criterion(output['forecast'], batch_y)
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
            
            avg_loss = epoch_loss / (len(X_train) // 8)
            train_losses.append(avg_loss)
            print(f"Epoch {epoch+1}/10, Loss: {avg_loss:.6f}")
        
        # 8. ëª¨ë¸ ë° ë©”íƒ€ë°ì´í„° ìºì‹œ ì €ì¥
        if use_cache:
            metadata = {
                'train_losses': train_losses,
                'model_config': model_config,
                'data_shape': {'X': X.shape, 'y': y.shape},
                'split_idx': split_idx
            }
            
            save_model_cache(model, scaler_data, metadata, cache_dir)
            save_metadata(csv_path, current_checksum, cache_dir)
    
    elif data_updated and use_cache:
        print("=== ë°ì´í„° ì—…ë°ì´íŠ¸ ê°ì§€: ì¦ë¶„ í•™ìŠµ ìˆ˜í–‰ ===")
        optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)  # ë‚®ì€ í•™ìŠµë¥ 
        criterion = nn.MSELoss()
        
        # ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ì¦ë¶„ í•™ìŠµ
        new_train_losses = incremental_training(model, X_train, y_train, optimizer, criterion, epochs=5)
        train_losses.extend(new_train_losses)
        
        # ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ ìºì‹œ ì €ì¥
        metadata = {
            'train_losses': train_losses,
            'model_config': model_config,
            'data_shape': {'X': X.shape, 'y': y.shape},
            'split_idx': split_idx
        }
        
        save_model_cache(model, scaler_data, metadata, cache_dir)
        save_metadata(csv_path, current_checksum, cache_dir)
    
    # 9. ì´ìƒ íƒì§€
    print("ì´ìƒ íƒì§€ ìˆ˜í–‰ ì¤‘...")
    model.eval()
    thres = DynamicThreshold()
    
    all_anomaly_scores = []
    all_predictions = []
    
    with torch.no_grad():
        for i in range(0, len(X_test), 8):
            batch_x = X_test[i:i+8]
            batch_y = y_test[i:i+8]
            
            output = model(batch_x, batch_y)
            
            if output['anomaly_score'] is not None:
                all_anomaly_scores.extend(output['anomaly_score'].cpu().numpy())
            all_predictions.extend(output['forecast'].cpu().numpy())
    
    # 10. ë™ì  ì„ê³„ê°’ ê³„ì‚°
    all_anomaly_scores = np.array(all_anomaly_scores)
    threshold = thres.update(torch.tensor(all_anomaly_scores))
    anomaly_mask = all_anomaly_scores > threshold
    
    # 11. ê²°ê³¼ ì¶œë ¥
    print(f"\n=== ì´ìƒ íƒì§€ ê²°ê³¼ ===")
    print(f"ì´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(all_anomaly_scores)}")
    print(f"ì´ìƒ ìƒ˜í”Œ ìˆ˜: {anomaly_mask.sum()}")
    print(f"ì´ìƒë¥ : {anomaly_mask.mean():.2%}")
    print(f"ë™ì  ì„ê³„ê°’: {threshold:.6f}")
    print(f"í‰ê·  ì´ìƒ ì ìˆ˜: {all_anomaly_scores.mean():.6f}")
    print(f"ìµœëŒ€ ì´ìƒ ì ìˆ˜: {all_anomaly_scores.max():.6f}")
    
    # 12. ì‹œê°í™”
    if use_interactive:
        print("\n=== ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘ ===")
        try:
            # ë°ì´í„° íƒìƒ‰ ëŒ€ì‹œë³´ë“œ
            print("1. ë°ì´í„° íƒìƒ‰ ëŒ€ì‹œë³´ë“œ...")
            create_interactive_dashboard(csv_path)
            
            # Plotly ì •ì  ëŒ€ì‹œë³´ë“œ (ë°±ì—…)
            print("2. Plotly ì •ì  ëŒ€ì‹œë³´ë“œ...")
            create_plotly_dashboard(csv_path)
            
            # ëª¨ë¸ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ (í•™ìŠµ ì†ì‹¤ í¬í•¨)
            print("3. ëª¨ë¸ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ...")
            create_model_performance_dashboard(model, all_anomaly_scores, anomaly_mask, threshold, df, train_losses)
            
        except Exception as e:
            print(f"ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™” ì˜¤ë¥˜: {e}")
            print("ê¸°ë³¸ matplotlib ì‹œê°í™”ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            use_interactive = False
    
    if not use_interactive:
        # ê¸°ë³¸ matplotlib ì‹œê°í™”
        create_basic_visualization(all_anomaly_scores, anomaly_mask, threshold, df, train_losses)
    
    return model, all_anomaly_scores, anomaly_mask, threshold, df
def create_interactive_dashboard(csv_path='sample_manufacturing.csv'):
    """ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ ìƒì„± - í™˜ê²½ì— ë§ëŠ” ìµœì í™”ëœ ë²„ì „"""
    df = pd.read_csv(csv_path)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    # ê³ ìœ ê°’ë“¤ ì¶”ì¶œ
    equipment_ids = ['All'] + sorted(df['eqp_id'].unique().tolist())
    chamber_ids = ['All'] + sorted(df['chamber_id'].unique().tolist())
    recipes = ['All'] + sorted(df['recipe'].unique().tolist())
    
    print("=== ì¸í„°ë™í‹°ë¸Œ ì´ìƒì¹˜ ë¶„ì„ ì‹œì‘ ===")
    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜:")
    print(f"Equipment IDs: {equipment_ids}")
    print(f"Chamber IDs: {chamber_ids}")
    print(f"Recipes: {recipes}")
    
    def update_plots(equipment_id='All', chamber_id='All', recipe='All'):
        # ë°ì´í„° í•„í„°ë§
        filtered_df = df.copy()
        
        if equipment_id != 'All':
            filtered_df = filtered_df[filtered_df['eqp_id'] == equipment_id]
        if chamber_id != 'All':
            filtered_df = filtered_df[filtered_df['chamber_id'] == chamber_id]
        if recipe != 'All':
            filtered_df = filtered_df[filtered_df['recipe'] == recipe]
        
        if len(filtered_df) == 0:
            print("âš ï¸ ì„ íƒëœ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\n=== í•„í„° ì¡°ê±´: Equipment={equipment_id}, Chamber={chamber_id}, Recipe={recipe} ===")
        
        # ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig = make_subplots(
            rows=3, cols=2,
            subplot_titles=(
                'Temperature Over Time', 'Pressure Over Time',
                'RF Power Over Time', 'Chamber Load Over Time',
                'Temperature vs RF Power', 'Anomaly Detection'
            ),
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        # 1. ì˜¨ë„ ì‹œê³„ì—´
        fig.add_trace(
            go.Scatter(x=filtered_df['timestamp'], y=filtered_df['TEMP'],
                      mode='lines', name='Temperature', line=dict(color='red')),
            row=1, col=1
        )
        
        # 2. ì••ë ¥ ì‹œê³„ì—´
        fig.add_trace(
            go.Scatter(x=filtered_df['timestamp'], y=filtered_df['PRESSURE'],
                      mode='lines', name='Pressure', line=dict(color='blue')),
            row=1, col=2
        )
        
        # 3. RF íŒŒì›Œ ì‹œê³„ì—´
        fig.add_trace(
            go.Scatter(x=filtered_df['timestamp'], y=filtered_df['RF_POWER'],
                      mode='lines', name='RF Power', line=dict(color='green')),
            row=2, col=1
        )
        
        # 4. ì±”ë²„ ë¡œë“œ ì‹œê³„ì—´
        fig.add_trace(
            go.Scatter(x=filtered_df['timestamp'], y=filtered_df['CHAMBER_LOAD'],
                      mode='lines', name='Chamber Load', line=dict(color='purple')),
            row=2, col=2
        )
        
        # 5. ì˜¨ë„ vs RF íŒŒì›Œ ì‚°ì ë„ (ë ˆì‹œí”¼ë³„ ìƒ‰ìƒ)
        for recipe_type in filtered_df['recipe'].unique():
            recipe_data = filtered_df[filtered_df['recipe'] == recipe_type]
            fig.add_trace(
                go.Scatter(x=recipe_data['TEMP'], y=recipe_data['RF_POWER'],
                          mode='markers', name=f'Recipe {recipe_type}',
                          marker=dict(size=4, opacity=0.6)),
                row=3, col=1
            )
        
        # 6. ì´ìƒì¹˜ íƒì§€ ê²°ê³¼
        # ì„ê³„ê°’ ê¸°ë°˜ ì´ìƒì¹˜
        temp_anomalies = filtered_df[filtered_df['TEMP'] > 450]
        power_anomalies = filtered_df[filtered_df['RF_POWER'] > 300]
        
        # ì •ìƒ ë°ì´í„°
        normal_data = filtered_df[
            (filtered_df['TEMP'] <= 450) & (filtered_df['RF_POWER'] <= 300)
        ]
        
        fig.add_trace(
            go.Scatter(x=normal_data['timestamp'], y=normal_data['TEMP'],
                      mode='markers', name='Normal', 
                      marker=dict(color='blue', size=3, opacity=0.5)),
            row=3, col=2
        )
        
        if len(temp_anomalies) > 0:
            fig.add_trace(
                go.Scatter(x=temp_anomalies['timestamp'], y=temp_anomalies['TEMP'],
                          mode='markers', name='Temp Anomaly',
                          marker=dict(color='red', size=6, symbol='x')),
                row=3, col=2
            )
        
        # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
        fig.update_layout(
            height=900,
            title_text=f"Manufacturing Data Analysis - Equipment: {equipment_id}, Chamber: {chamber_id}, Recipe: {recipe}",
            showlegend=True
        )
        
        # ì¶• ë¼ë²¨ ì¶”ê°€
        fig.update_xaxes(title_text="Time", row=1, col=1)
        fig.update_xaxes(title_text="Time", row=1, col=2)
        fig.update_xaxes(title_text="Time", row=2, col=1)
        fig.update_xaxes(title_text="Time", row=2, col=2)
        fig.update_xaxes(title_text="Temperature", row=3, col=1)
        fig.update_xaxes(title_text="Time", row=3, col=2)
        
        fig.update_yaxes(title_text="Temperature (Â°C)", row=1, col=1)
        fig.update_yaxes(title_text="Pressure", row=1, col=2)
        fig.update_yaxes(title_text="RF Power", row=2, col=1)
        fig.update_yaxes(title_text="Chamber Load", row=2, col=2)
        fig.update_yaxes(title_text="RF Power", row=3, col=1)
        fig.update_yaxes(title_text="Temperature (Â°C)", row=3, col=2)
        
        # í†µê³„ ì •ë³´ ì¶œë ¥
        print(f"\nğŸ“Š í•„í„°ë§ëœ ë°ì´í„° í†µê³„")
        print(f"   ë°ì´í„° í¬ì¸íŠ¸: {len(filtered_df):,}")
        print(f"   ì˜¨ë„ ë²”ìœ„: {filtered_df['TEMP'].min():.1f} - {filtered_df['TEMP'].max():.1f}Â°C")
        print(f"   ì••ë ¥ ë²”ìœ„: {filtered_df['PRESSURE'].min():.2f} - {filtered_df['PRESSURE'].max():.2f}")
        print(f"   RF íŒŒì›Œ ë²”ìœ„: {filtered_df['RF_POWER'].min():.1f} - {filtered_df['RF_POWER'].max():.1f}")
        print(f"   ğŸ”¥ ì˜¨ë„ ì´ìƒì¹˜: {len(temp_anomalies)}ê°œ")
        print(f"   âš¡ RF íŒŒì›Œ ì´ìƒì¹˜: {len(power_anomalies)}ê°œ")
        
        # ê·¸ë˜í”„ í‘œì‹œ
        try:
            fig.show()
        except Exception as e:
            print(f"âš ï¸ ê·¸ë˜í”„ í‘œì‹œ ì˜¤ë¥˜: {e}")
            print("ë¸Œë¼ìš°ì €ì—ì„œ ê·¸ë˜í”„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    # í™˜ê²½ ê°ì§€ ë° ì ì ˆí•œ ì¸í„°í˜ì´ìŠ¤ ì œê³µ
    environment_type = detect_environment()
    print(f"\nğŸ” ê°ì§€ëœ í™˜ê²½: {environment_type}")
    
    if environment_type == "jupyter":
        try:
            create_jupyter_widgets(equipment_ids, chamber_ids, recipes, update_plots)
        except Exception as e:
            print(f"âš ï¸ Jupyter ìœ„ì ¯ ìƒì„± ì‹¤íŒ¨: {e}")
            print("ëŒ€ì•ˆ ì¸í„°í˜ì´ìŠ¤ë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
            create_enhanced_manual_interface(df, equipment_ids, chamber_ids, recipes, update_plots)
    elif environment_type == "vscode":
        # VS Codeì—ì„œëŠ” ìˆ˜ë™ ì¸í„°í˜ì´ìŠ¤ê°€ ë” ë‚˜ìŒ
        print("VS Code í™˜ê²½ì—ì„œëŠ” ìˆ˜ë™ ì„ íƒ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        create_enhanced_manual_interface(df, equipment_ids, chamber_ids, recipes, update_plots)
    else:
        # ê¸°ë³¸ í™˜ê²½ì—ì„œëŠ” ìˆ˜ë™ ì¸í„°í˜ì´ìŠ¤
        print("ê¸°ë³¸ í™˜ê²½ì—ì„œëŠ” ìˆ˜ë™ ì„ íƒ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        create_enhanced_manual_interface(df, equipment_ids, chamber_ids, recipes, update_plots)

def detect_environment():
    """í˜„ì¬ ì‹¤í–‰ í™˜ê²½ ê°ì§€"""
    try:
        # Jupyter í™˜ê²½ í™•ì¸
        from IPython import get_ipython
        if get_ipython() is not None:
            ipython = get_ipython()
            if hasattr(ipython, 'kernel'):
                return "jupyter"
    except ImportError:
        pass
    
    # VS Code í™˜ê²½ í™•ì¸
    import os
    if 'VSCODE_PID' in os.environ or 'TERM_PROGRAM' in os.environ:
        return "vscode"
    
    return "terminal"

def create_jupyter_widgets(equipment_ids, chamber_ids, recipes, update_plots):
    """Jupyter í™˜ê²½ìš© ìœ„ì ¯ ìƒì„±"""
    from IPython.display import display, clear_output
    
    # ì¸í„°ë™í‹°ë¸Œ ìœ„ì ¯ ìƒì„±
    equipment_dropdown = widgets.Dropdown(
        options=equipment_ids,
        value='All',
        description='Equipment:',
        style={'description_width': 'initial'}
    )
    
    chamber_dropdown = widgets.Dropdown(
        options=chamber_ids,
        value='All',
        description='Chamber:',
        style={'description_width': 'initial'}
    )
    
    recipe_dropdown = widgets.Dropdown(
        options=recipes,
        value='All',
        description='Recipe:',
        style={'description_width': 'initial'}
    )
    
    print("ì¸í„°ë™í‹°ë¸Œ ìœ„ì ¯ì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ë¥¼ ë¶„ì„í•˜ì„¸ìš”:")
    
    # ìœ„ì ¯ ë°•ìŠ¤ë¡œ ë ˆì´ì•„ì›ƒ ê°œì„ 
    widget_box = widgets.HBox([equipment_dropdown, chamber_dropdown, recipe_dropdown])
    display(widget_box)
    
    # ì¸í„°ë™í‹°ë¸Œ ë””ìŠ¤í”Œë ˆì´
    interact(update_plots, 
             equipment_id=equipment_dropdown,
             chamber_id=chamber_dropdown,
             recipe=recipe_dropdown)

def create_enhanced_manual_interface(df, equipment_ids, chamber_ids, recipes, update_plots_func):
    """í–¥ìƒëœ ìˆ˜ë™ í•„í„° ì„ íƒ ì¸í„°í˜ì´ìŠ¤"""
    
    print("\n=== ğŸ›ï¸ ìˆ˜ë™ í•„í„° ì„ íƒ ì¸í„°í˜ì´ìŠ¤ ===")
    print("ì›í•˜ëŠ” ì¡°ê±´ì„ ì„ íƒí•˜ì—¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì„¸ìš”.")
    print("(Enterë¥¼ ëˆ„ë¥´ë©´ ê¸°ë³¸ê°’ 'All' ì‚¬ìš©, 'quit'ìœ¼ë¡œ ì¢…ë£Œ)")
    
    # ì˜µì…˜ì„ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
    def print_options(title, options):
        print(f"\nğŸ“‹ {title}:")
        for i, option in enumerate(options, 1):
            if i <= 5:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                print(f"   {i}. {option}")
            elif i == 6 and len(options) > 6:
                print(f"   ... ì´ {len(options)}ê°œ ì˜µì…˜")
                break
        print(f"   ğŸ’¡ ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”")
    
    while True:
        print("\n" + "="*50)
        
        # Equipment ì„ íƒ
        print_options("Equipment ì˜µì…˜", equipment_ids)
        eqp_input = input("ğŸ­ Equipmentë¥¼ ì„ íƒí•˜ì„¸ìš” [ê¸°ë³¸ê°’: All]: ").strip() or "All"
        if eqp_input.lower() == 'quit':
            break
        
        # ë²ˆí˜¸ë¡œ ì„ íƒí•œ ê²½ìš° ì²˜ë¦¬
        if eqp_input.isdigit():
            idx = int(eqp_input) - 1
            if 0 <= idx < len(equipment_ids):
                eqp_choice = equipment_ids[idx]
            else:
                print(f"âš ï¸ ì˜ëª»ëœ ë²ˆí˜¸: {eqp_input}")
                continue
        else:
            eqp_choice = eqp_input
        
        if eqp_choice not in equipment_ids:
            print(f"âš ï¸ ì˜ëª»ëœ Equipment ID: {eqp_choice}")
            print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜: {', '.join(equipment_ids[:5])}...")
            continue
            
        # Chamber ì„ íƒ
        print_options("Chamber ì˜µì…˜", chamber_ids)
        chamber_input = input("ğŸ  Chamberë¥¼ ì„ íƒí•˜ì„¸ìš” [ê¸°ë³¸ê°’: All]: ").strip() or "All"
        if chamber_input.lower() == 'quit':
            break
            
        # ë²ˆí˜¸ë¡œ ì„ íƒí•œ ê²½ìš° ì²˜ë¦¬
        if chamber_input.isdigit():
            idx = int(chamber_input) - 1
            if 0 <= idx < len(chamber_ids):
                chamber_choice = chamber_ids[idx]
            else:
                print(f"âš ï¸ ì˜ëª»ëœ ë²ˆí˜¸: {chamber_input}")
                continue
        else:
            chamber_choice = chamber_input
            
        if chamber_choice not in chamber_ids:
            print(f"âš ï¸ ì˜ëª»ëœ Chamber ID: {chamber_choice}")
            print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜: {', '.join(chamber_ids)}")
            continue
            
        # Recipe ì„ íƒ
        print_options("Recipe ì˜µì…˜", recipes)
        recipe_input = input("ğŸ“ Recipeë¥¼ ì„ íƒí•˜ì„¸ìš” [ê¸°ë³¸ê°’: All]: ").strip() or "All"
        if recipe_input.lower() == 'quit':
            break
            
        # ë²ˆí˜¸ë¡œ ì„ íƒí•œ ê²½ìš° ì²˜ë¦¬
        if recipe_input.isdigit():
            idx = int(recipe_input) - 1
            if 0 <= idx < len(recipes):
                recipe_choice = recipes[idx]
            else:
                print(f"âš ï¸ ì˜ëª»ëœ ë²ˆí˜¸: {recipe_input}")
                continue
        else:
            recipe_choice = recipe_input
            
        if recipe_choice not in recipes:
            print(f"âš ï¸ ì˜ëª»ëœ Recipe: {recipe_choice}")
            print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜: {', '.join(recipes[:5])}...")
            continue
        
        # ì„ íƒëœ í•„í„°ë¡œ ë¶„ì„ ì‹¤í–‰
        print(f"\nğŸ” ë¶„ì„ ì‹¤í–‰ì¤‘...")
        print(f"   Equipment: {eqp_choice}")
        print(f"   Chamber: {chamber_choice}")
        print(f"   Recipe: {recipe_choice}")
        
        try:
            update_plots_func(eqp_choice, chamber_choice, recipe_choice)
            print("âœ… ë¶„ì„ ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ê³„ì†í• ì§€ ë¬»ê¸°
        print("\n" + "-"*50)
        continue_choice = input("ğŸ”„ ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ë¶„ì„í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n) [ê¸°ë³¸ê°’: n]: ").strip().lower()
        if continue_choice not in ['y', 'yes']:
            break
    
    print("\nğŸ‘‹ ì¸í„°ë™í‹°ë¸Œ ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

def create_model_performance_dashboard(model, all_anomaly_scores, anomaly_mask, threshold, df, train_losses=None):
    """ëª¨ë¸ ì„±ëŠ¥ ì‹œê°í™” ëŒ€ì‹œë³´ë“œ"""
    
    fig = make_subplots(
        rows=2, cols=3,
        subplot_titles=(
            'Anomaly Score Time Series', 'Anomaly Score Distribution',
            'Model Performance Metrics', 'Feature Correlation Heatmap',
            'Anomaly Detection Results', 'Training Loss Evolution'
        ),
        specs=[[{"secondary_y": False}, {"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # 1. ì´ìƒ ì ìˆ˜ ì‹œê³„ì—´
    fig.add_trace(
        go.Scatter(y=all_anomaly_scores, mode='lines', name='Anomaly Score',
                  line=dict(color='blue', width=1)),
        row=1, col=1
    )
    fig.add_hline(y=threshold, line_dash="dash", line_color="red", 
                  annotation_text=f"Threshold: {threshold:.4f}", row=1, col=1)
    
    # ì´ìƒì¹˜ í¬ì¸íŠ¸ ê°•ì¡°
    anomaly_indices = np.where(anomaly_mask)[0]
    if len(anomaly_indices) > 0:
        fig.add_trace(
            go.Scatter(x=anomaly_indices, y=all_anomaly_scores[anomaly_indices],
                      mode='markers', name='Detected Anomalies',
                      marker=dict(color='red', size=6, symbol='x')),
            row=1, col=1
        )
    
    # 2. ì´ìƒ ì ìˆ˜ ë¶„í¬
    fig.add_trace(
        go.Histogram(x=all_anomaly_scores, nbinsx=50, name='Score Distribution',
                    marker=dict(color='lightblue', line=dict(color='black', width=1))),
        row=1, col=2
    )
    fig.add_vline(x=threshold, line_dash="dash", line_color="red", row=1, col=2)
    
    # 3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ê°€ìƒ ë°ì´í„°)
    metrics = ['Precision', 'Recall', 'F1-Score', 'Accuracy']
    values = [0.85, 0.78, 0.81, 0.92]  # ì˜ˆì‹œ ê°’
    
    fig.add_trace(
        go.Bar(x=metrics, y=values, name='Performance Metrics',
               marker=dict(color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])),
        row=1, col=3
    )
    
    # 4. íŠ¹ì„± ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
    features = ['TEMP', 'PRESSURE', 'RF_POWER', 'CHAMBER_LOAD']
    corr_matrix = df[features].corr().values
    
    fig.add_trace(
        go.Heatmap(z=corr_matrix, x=features, y=features,
                  colorscale='RdBu', zmid=0, name='Correlation'),
        row=2, col=1
    )
    
    # 5. ì´ìƒ íƒì§€ ê²°ê³¼ ìš”ì•½
    detection_summary = {
        'Normal': len(all_anomaly_scores) - anomaly_mask.sum(),
        'Anomaly': anomaly_mask.sum()
    }
    
    fig.add_trace(
        go.Pie(labels=list(detection_summary.keys()), 
               values=list(detection_summary.values()),
               name="Detection Results"),
        row=2, col=2
    )
    
    # 6. í•™ìŠµ ì†ì‹¤ ì§„í™”
    if train_losses:
        fig.add_trace(
            go.Scatter(y=train_losses, mode='lines+markers', name='Training Loss',
                      line=dict(color='orange', width=2)),
            row=2, col=3
        )
    else:
        # ì„ê³„ê°’ ì§„í™” (ì‹œë®¬ë ˆì´ì…˜)
        threshold_evolution = [threshold * (1 + 0.1 * np.sin(i/10)) for i in range(100)]
        fig.add_trace(
            go.Scatter(y=threshold_evolution, mode='lines', name='Dynamic Threshold',
                      line=dict(color='orange', width=2)),
            row=2, col=3
        )
    
    # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
    fig.update_layout(
        height=800,
        title_text="Model Performance Dashboard",
        showlegend=True
    )
    
    # ì¶• ë¼ë²¨
    fig.update_xaxes(title_text="Time Steps", row=1, col=1)
    fig.update_yaxes(title_text="Anomaly Score", row=1, col=1)
    fig.update_xaxes(title_text="Anomaly Score", row=1, col=2)
    fig.update_yaxes(title_text="Frequency", row=1, col=2)
    fig.update_yaxes(title_text="Score", row=1, col=3)
    fig.update_xaxes(title_text="Epoch", row=2, col=3)
    fig.update_yaxes(title_text="Loss" if train_losses else "Threshold", row=2, col=3)
    
    fig.show()

# ìºì‹œ ê´€ë¦¬ í•¨ìˆ˜ë“¤
def get_data_checksum(csv_path):
    """ë°ì´í„° íŒŒì¼ì˜ ì²´í¬ì„¬ì„ ê³„ì‚°"""
    with open(csv_path, 'rb') as f:
        file_content = f.read()
    return hashlib.md5(file_content).hexdigest()

def save_model_cache(model, scaler_data, metadata, cache_dir='cache'):
    """ëª¨ë¸ê³¼ ê´€ë ¨ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥"""
    os.makedirs(cache_dir, exist_ok=True)
    
    # ëª¨ë¸ ì €ì¥
    model_path = os.path.join(cache_dir, 'model.pth')
    torch.save(model.state_dict(), model_path)
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ë° ë©”íƒ€ë°ì´í„° ì €ì¥
    cache_data = {
        'scaler_data': scaler_data,
        'metadata': metadata,
        'saved_time': datetime.now().isoformat()
    }
    
    cache_path = os.path.join(cache_dir, 'cache_data.pkl')
    with open(cache_path, 'wb') as f:
        pickle.dump(cache_data, f)
    
    print(f"ëª¨ë¸ ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_dir}")

def load_model_cache(model_config, cache_dir='cache'):
    """ìºì‹œì—ì„œ ëª¨ë¸ê³¼ ê´€ë ¨ ë°ì´í„°ë¥¼ ë¡œë“œ"""
    model_path = os.path.join(cache_dir, 'model.pth')
    cache_path = os.path.join(cache_dir, 'cache_data.pkl')
    
    if not (os.path.exists(model_path) and os.path.exists(cache_path)):
        return None, None
    
    try:
        # ëª¨ë¸ ë¡œë“œ
        model = InformerAutoformerHybrid(**model_config)
        model.load_state_dict(torch.load(model_path))
        model.eval()
        
        # ìºì‹œ ë°ì´í„° ë¡œë“œ
        with open(cache_path, 'rb') as f:
            cache_data = pickle.load(f)
        
        print(f"ëª¨ë¸ ìºì‹œ ë¡œë“œ ì™„ë£Œ: {cache_data['saved_time']}")
        return model, cache_data
    
    except Exception as e:
        print(f"ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

def check_data_update(csv_path, cache_dir='cache'):
    """ë°ì´í„° ì—…ë°ì´íŠ¸ ì—¬ë¶€ í™•ì¸"""
    metadata_path = os.path.join(cache_dir, 'metadata.json')
    current_checksum = get_data_checksum(csv_path)
    
    if not os.path.exists(metadata_path):
        return True, current_checksum  # ì²« ì‹¤í–‰
    
    try:
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        
        cached_checksum = metadata.get('data_checksum', '')
        return current_checksum != cached_checksum, current_checksum
    
    except Exception as e:
        print(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return True, current_checksum

def save_metadata(csv_path, checksum, cache_dir='cache'):
    """ë©”íƒ€ë°ì´í„° ì €ì¥"""
    os.makedirs(cache_dir, exist_ok=True)
    metadata_path = os.path.join(cache_dir, 'metadata.json')
    
    metadata = {
        'data_checksum': checksum,
        'data_path': csv_path,
        'last_update': datetime.now().isoformat()
    }
    
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2)

def incremental_training(model, new_X, new_y, optimizer, criterion, epochs=5):
    """ì¦ë¶„ í•™ìŠµ ìˆ˜í–‰"""
    print("ì¦ë¶„ í•™ìŠµ ì‹œì‘...")
    model.train()
    train_losses = []
    
    for epoch in range(epochs):
        epoch_loss = 0
        for i in range(0, len(new_X), 8):
            batch_x = new_X[i:i+8]
            batch_y = new_y[i:i+8]
            
            optimizer.zero_grad()
            output = model(batch_x, batch_y)
            loss = criterion(output['forecast'], batch_y)
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
        
        avg_loss = epoch_loss / max(1, len(new_X) // 8)
        train_losses.append(avg_loss)
        print(f"Incremental Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}")
    
    return train_losses

def create_basic_visualization(all_anomaly_scores, anomaly_mask, threshold, df, train_losses):
    """ê¸°ë³¸ matplotlib ì‹œê°í™”"""
    plt.figure(figsize=(15, 10))
    
    # í•™ìŠµ ì†ì‹¤
    plt.subplot(2, 2, 1)
    plt.plot(train_losses)
    plt.title('Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('MSE Loss')
    plt.grid(True)
    
    # ì´ìƒ ì ìˆ˜ ë¶„í¬
    plt.subplot(2, 2, 2)
    plt.hist(all_anomaly_scores, bins=50, alpha=0.7, label='Anomaly Scores')
    plt.axvline(threshold, color='r', linestyle='--', label=f'Threshold: {threshold:.4f}')
    plt.title('Anomaly Score Distribution')
    plt.xlabel('Anomaly Score')
    plt.ylabel('Frequency')
    plt.legend()
    plt.grid(True)
    
    # ì‹œê³„ì—´ ì´ìƒ ì ìˆ˜
    plt.subplot(2, 2, 3)
    plt.plot(all_anomaly_scores, alpha=0.7)
    plt.axhline(threshold, color='r', linestyle='--', label=f'Threshold: {threshold:.4f}')
    anomaly_indices = np.where(anomaly_mask)[0]
    plt.scatter(anomaly_indices, all_anomaly_scores[anomaly_indices], 
               color='red', s=30, label=f'Anomalies ({len(anomaly_indices)})')
    plt.title('Time Series Anomaly Detection')
    plt.xlabel('Time Steps')
    plt.ylabel('Anomaly Score')
    plt.legend()
    plt.grid(True)
    
    # ì›ë³¸ ë°ì´í„°ì˜ ì´ìƒì¹˜ ìœ„ì¹˜ í‘œì‹œ
    plt.subplot(2, 2, 4)
    temp_data = df['TEMP'].values
    plt.plot(temp_data, alpha=0.7, label='Temperature')
    
    # ì‹¤ì œ ë°ì´í„°ì—ì„œ ì˜¨ë„ ì´ìƒì¹˜ ì°¾ê¸°
    temp_anomalies = np.where(temp_data > 450)[0]
    plt.scatter(temp_anomalies, temp_data[temp_anomalies], 
               color='red', s=30, label=f'Temp Anomalies ({len(temp_anomalies)})')
    plt.title('Original Temperature Data with Anomalies')
    plt.xlabel('Time Steps')
    plt.ylabel('Temperature')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.show()
    
def analyze_anomalies_by_groups(df, temp_anomalies, power_anomalies, scores, mask):
    """ì¥ë¹„/ì±”ë²„/ë ˆì‹œí”¼ë³„ ì´ìƒì¹˜ ë¶„ì„"""
    print(f"\n=== ê·¸ë£¹ë³„ ì´ìƒì¹˜ ë¶„ì„ ===")
    
    # ì¥ë¹„ë³„ ì´ìƒì¹˜
    print("ì¥ë¹„ë³„ ì˜¨ë„ ì´ìƒì¹˜:")
    eqp_temp_anomalies = temp_anomalies.groupby('eqp_id').size()
    for eqp_id, count in eqp_temp_anomalies.items():
        total_eqp_data = len(df[df['eqp_id'] == eqp_id])
        print(f"  {eqp_id}: {count}ê°œ ({count/total_eqp_data:.2%})")
    
    # ì±”ë²„ë³„ ì´ìƒì¹˜
    print("\nì±”ë²„ë³„ ì˜¨ë„ ì´ìƒì¹˜:")
    chamber_temp_anomalies = temp_anomalies.groupby('chamber_id').size()
    for chamber_id, count in chamber_temp_anomalies.items():
        total_chamber_data = len(df[df['chamber_id'] == chamber_id])
        print(f"  {chamber_id}: {count}ê°œ ({count/total_chamber_data:.2%})")
    
    # ë ˆì‹œí”¼ë³„ ì´ìƒì¹˜
    print("\në ˆì‹œí”¼ë³„ ì˜¨ë„ ì´ìƒì¹˜:")
    recipe_temp_anomalies = temp_anomalies.groupby('recipe').size()
    for recipe, count in recipe_temp_anomalies.items():
        total_recipe_data = len(df[df['recipe'] == recipe])
        print(f"  {recipe}: {count}ê°œ ({count/total_recipe_data:.2%})")
    
    # ì‹œê°„ëŒ€ë³„ ì´ìƒì¹˜ íŒ¨í„´
    df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
    temp_anomalies['hour'] = pd.to_datetime(temp_anomalies['timestamp']).dt.hour
    
    print("\nì‹œê°„ëŒ€ë³„ ì´ìƒì¹˜ ë¶„í¬:")
    hourly_anomalies = temp_anomalies.groupby('hour').size()
    peak_hours = hourly_anomalies.nlargest(3)
    for hour, count in peak_hours.items():
        print(f"  {hour:02d}ì‹œ: {count}ê°œ")

def create_anomaly_analysis_dashboard(df, scores, mask, threshold):
    """ì¸í„°ë™í‹°ë¸Œ ì´ìƒì¹˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ"""
    
    # ê³ ìœ ê°’ë“¤ ì¶”ì¶œ
    equipment_ids = ['All'] + sorted(df['eqp_id'].unique().tolist())
    chamber_ids = ['All'] + sorted(df['chamber_id'].unique().tolist())
    recipes = ['All'] + sorted(df['recipe'].unique().tolist())
    
    print(f"\n=== ì´ìƒì¹˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ ===")
    print(f"Equipment ì˜µì…˜: {equipment_ids}")
    print(f"Chamber ì˜µì…˜: {chamber_ids}")
    print(f"Recipe ì˜µì…˜: {recipes}")
    
    def analyze_filtered_anomalies(equipment_id='All', chamber_id='All', recipe='All'):
        # ë°ì´í„° í•„í„°ë§
        filtered_df = df.copy()
        filter_conditions = []
        
        if equipment_id != 'All':
            filtered_df = filtered_df[filtered_df['eqp_id'] == equipment_id]
            filter_conditions.append(f"Equipment: {equipment_id}")
        if chamber_id != 'All':
            filtered_df = filtered_df[filtered_df['chamber_id'] == chamber_id]
            filter_conditions.append(f"Chamber: {chamber_id}")
        if recipe != 'All':
            filtered_df = filtered_df[filtered_df['recipe'] == recipe]
            filter_conditions.append(f"Recipe: {recipe}")
        
        if len(filtered_df) == 0:
            print("ì„ íƒëœ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # í•„í„° ì¡°ê±´ ì¶œë ¥
        filter_str = " & ".join(filter_conditions) if filter_conditions else "ì „ì²´ ë°ì´í„°"
        print(f"\n=== í•„í„° ì¡°ê±´: {filter_str} ===")
        
        # í•„í„°ë§ëœ ë°ì´í„°ì˜ ì¸ë±ìŠ¤ ë²”ìœ„ ê³„ì‚°
        filtered_indices = filtered_df.index.tolist()
        
        # ì„ê³„ê°’ ê¸°ë°˜ ì´ìƒì¹˜
        temp_anomalies = filtered_df[filtered_df['TEMP'] > 450]
        power_anomalies = filtered_df[filtered_df['RF_POWER'] > 300]
        
        # ëª¨ë¸ íƒì§€ ì´ìƒì¹˜ (ê·¼ì‚¬ì ìœ¼ë¡œ ë§¤í•‘)
        # ì‹œí€€ìŠ¤ ë°ì´í„°ì™€ ì›ë³¸ ë°ì´í„° ê°„ì˜ ë§¤í•‘ì´ ë³µì¡í•˜ë¯€ë¡œ ë¹„ìœ¨ë¡œ ì¶”ì •
        seq_start_idx = 96  # ì‹œí€€ìŠ¤ ê¸¸ì´
        total_original_data = len(df)
        total_test_data = len(scores)
        
        # í•„í„°ë§ëœ ë°ì´í„°ì—ì„œ ì˜ˆìƒë˜ëŠ” ëª¨ë¸ ì´ìƒì¹˜ ìˆ˜ ì¶”ì •
        filtered_ratio = len(filtered_df) / total_original_data
        estimated_model_anomalies = int(mask.sum() * filtered_ratio)
        
        # ì‹œê°í™” ìƒì„±
        fig = make_subplots(
            rows=3, cols=2,
            subplot_titles=(
                f'Temperature Time Series ({filter_str})',
                f'RF Power Time Series ({filter_str})',
                f'Temperature vs RF Power Scatter',
                f'Anomaly Distribution by Hour',
                f'Feature Statistics Comparison',
                f'Anomaly Summary'
            ),
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        # 1. ì˜¨ë„ ì‹œê³„ì—´ (ì´ìƒì¹˜ ê°•ì¡°)
        fig.add_trace(
            go.Scatter(x=filtered_df['timestamp'], y=filtered_df['TEMP'],
                      mode='lines', name='Temperature', 
                      line=dict(color='blue', width=1)),
            row=1, col=1
        )
        
        if len(temp_anomalies) > 0:
            fig.add_trace(
                go.Scatter(x=temp_anomalies['timestamp'], y=temp_anomalies['TEMP'],
                          mode='markers', name='Temp Anomalies',
                          marker=dict(color='red', size=8, symbol='x')),
                row=1, col=1
            )
        
        # ì„ê³„ê°’ ë¼ì¸
        fig.add_hline(y=450, line_dash="dash", line_color="red", 
                     annotation_text="Temp Threshold: 450Â°C", row=1, col=1)
        
        # 2. RF íŒŒì›Œ ì‹œê³„ì—´ (ì´ìƒì¹˜ ê°•ì¡°)
        fig.add_trace(
            go.Scatter(x=filtered_df['timestamp'], y=filtered_df['RF_POWER'],
                      mode='lines', name='RF Power',
                      line=dict(color='green', width=1)),
            row=1, col=2
        )
        
        if len(power_anomalies) > 0:
            fig.add_trace(
                go.Scatter(x=power_anomalies['timestamp'], y=power_anomalies['RF_POWER'],
                          mode='markers', name='Power Anomalies',
                          marker=dict(color='orange', size=8, symbol='triangle-up')),
                row=1, col=2
            )
        
        # RF íŒŒì›Œ ì„ê³„ê°’ ë¼ì¸
        fig.add_hline(y=300, line_dash="dash", line_color="orange",
                     annotation_text="RF Power Threshold: 300", row=1, col=2)
        
        # 3. ì˜¨ë„ vs RF íŒŒì›Œ ì‚°ì ë„ (ë ˆì‹œí”¼ë³„ ìƒ‰ìƒ)
        recipe_colors = {'R101': 'blue', 'R102': 'green', 'R103': 'purple'}
        for recipe_type in filtered_df['recipe'].unique():
            recipe_data = filtered_df[filtered_df['recipe'] == recipe_type]
            color = recipe_colors.get(recipe_type, 'gray')
            
            fig.add_trace(
                go.Scatter(x=recipe_data['TEMP'], y=recipe_data['RF_POWER'],
                          mode='markers', name=f'Recipe {recipe_type}',
                          marker=dict(size=4, opacity=0.6, color=color)),
                row=2, col=1
            )
        
        # ì´ìƒì¹˜ ì˜ì—­ í‘œì‹œ
        fig.add_hline(y=300, line_dash="dash", line_color="orange", row=2, col=1)
        fig.add_vline(x=450, line_dash="dash", line_color="red", row=2, col=1)
        
        # 4. ì‹œê°„ëŒ€ë³„ ì´ìƒì¹˜ ë¶„í¬
        if len(temp_anomalies) > 0:
            temp_anomalies_copy = temp_anomalies.copy()
            temp_anomalies_copy['hour'] = pd.to_datetime(temp_anomalies_copy['timestamp']).dt.hour
            hourly_dist = temp_anomalies_copy.groupby('hour').size().reset_index(name='count')
            
            fig.add_trace(
                go.Bar(x=hourly_dist['hour'], y=hourly_dist['count'],
                      name='Anomalies by Hour',
                      marker=dict(color='red', opacity=0.7)),
                row=2, col=2
            )
        
        # 5. íŠ¹ì„± í†µê³„ ë¹„êµ (ì •ìƒ vs ì´ìƒ)
        normal_data = filtered_df[
            (filtered_df['TEMP'] <= 450) & (filtered_df['RF_POWER'] <= 300)
        ]
        
        features = ['TEMP', 'PRESSURE', 'RF_POWER', 'CHAMBER_LOAD']
        normal_means = [normal_data[feat].mean() for feat in features]
        anomaly_means = [temp_anomalies[feat].mean() if len(temp_anomalies) > 0 else 0 for feat in features]
        
        fig.add_trace(
            go.Bar(x=features, y=normal_means, name='Normal Mean',
                  marker=dict(color='lightblue'), offsetgroup=1),
            row=3, col=1
        )
        
        fig.add_trace(
            go.Bar(x=features, y=anomaly_means, name='Anomaly Mean',
                  marker=dict(color='lightcoral'), offsetgroup=2),
            row=3, col=1
        )
        
        # 6. ì´ìƒì¹˜ ìš”ì•½ íŒŒì´ ì°¨íŠ¸
        anomaly_summary = {
            'Normal': len(filtered_df) - len(temp_anomalies) - len(power_anomalies),
            'Temp Anomaly': len(temp_anomalies),
            'Power Anomaly': len(power_anomalies)
        }
        
        # ì¤‘ë³µ ì œê±° (ì˜¨ë„ì™€ íŒŒì›Œ ëª¨ë‘ ì´ìƒì¸ ê²½ìš°)
        both_anomalies = len(filtered_df[
            (filtered_df['TEMP'] > 450) & (filtered_df['RF_POWER'] > 300)
        ])
        anomaly_summary['Both Anomalies'] = both_anomalies
        anomaly_summary['Normal'] += both_anomalies  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ì¡°ì •
        
        fig.add_trace(
            go.Pie(labels=list(anomaly_summary.keys()),
                  values=list(anomaly_summary.values()),
                  name="Anomaly Summary"),
            row=3, col=2
        )
        
        # ë ˆì´ì•„ì›ƒ ì—…ë°ì´íŠ¸
        fig.update_layout(
            height=1000,
            title_text=f"Anomaly Analysis Dashboard - {filter_str}",
            showlegend=True
        )
        
        # ì¶• ë¼ë²¨ ì„¤ì •
        fig.update_xaxes(title_text="Time", row=1, col=1)
        fig.update_yaxes(title_text="Temperature (Â°C)", row=1, col=1)
        fig.update_xaxes(title_text="Time", row=1, col=2)
        fig.update_yaxes(title_text="RF Power", row=1, col=2)
        fig.update_xaxes(title_text="Temperature (Â°C)", row=2, col=1)
        fig.update_yaxes(title_text="RF Power", row=2, col=1)
        fig.update_xaxes(title_text="Hour", row=2, col=2)
        fig.update_yaxes(title_text="Anomaly Count", row=2, col=2)
        fig.update_xaxes(title_text="Features", row=3, col=1)
        fig.update_yaxes(title_text="Average Value", row=3, col=1)
        
        # í†µê³„ ì •ë³´ ì¶œë ¥
        print(f"ë°ì´í„° í¬ì¸íŠ¸: {len(filtered_df):,}ê°œ")
        print(f"ì˜¨ë„ ë²”ìœ„: {filtered_df['TEMP'].min():.1f}Â°C - {filtered_df['TEMP'].max():.1f}Â°C")
        print(f"RF íŒŒì›Œ ë²”ìœ„: {filtered_df['RF_POWER'].min():.1f} - {filtered_df['RF_POWER'].max():.1f}")
        print(f"ì˜¨ë„ ì´ìƒì¹˜: {len(temp_anomalies)}ê°œ ({len(temp_anomalies)/len(filtered_df):.2%})")
        print(f"RF íŒŒì›Œ ì´ìƒì¹˜: {len(power_anomalies)}ê°œ ({len(power_anomalies)/len(filtered_df):.2%})")
        print(f"ì˜ˆìƒ ëª¨ë¸ íƒì§€ ì´ìƒì¹˜: ~{estimated_model_anomalies}ê°œ")
        
        # ìƒìœ„ ì´ìƒì¹˜ ì‹œì  ì¶œë ¥
        if len(temp_anomalies) > 0:
            print(f"\nìƒìœ„ ì˜¨ë„ ì´ìƒì¹˜ (ìµœëŒ€ 5ê°œ):")
            top_temp_anomalies = temp_anomalies.nlargest(5, 'TEMP')
            for idx, row in top_temp_anomalies.iterrows():
                print(f"  {row['timestamp']}: TEMP={row['TEMP']:.1f}Â°C, RF_POWER={row['RF_POWER']:.1f}, Recipe={row['recipe']}")
        
        fig.show()
        
        return filtered_df, temp_anomalies, power_anomalies
    
    # ìœ„ì ¯ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
    try:
        from IPython.display import display
        
        # ì¸í„°ë™í‹°ë¸Œ ìœ„ì ¯ ìƒì„±
        equipment_dropdown = widgets.Dropdown(
            options=equipment_ids,
            value='All',
            description='Equipment:',
            style={'description_width': 'initial'}
        )
        
        chamber_dropdown = widgets.Dropdown(
            options=chamber_ids,
            value='All',
            description='Chamber:',
            style={'description_width': 'initial'}
        )
        
        recipe_dropdown = widgets.Dropdown(
            options=recipes,
            value='All',
            description='Recipe:',
            style={'description_width': 'initial'}
        )
        
        # ì¸í„°ë™í‹°ë¸Œ ë””ìŠ¤í”Œë ˆì´
        print("ì¸í„°ë™í‹°ë¸Œ ìœ„ì ¯ì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ë¥¼ ë¶„ì„í•˜ì„¸ìš”:")
        interact(analyze_filtered_anomalies,
                equipment_id=equipment_dropdown,
                chamber_id=chamber_dropdown,
                recipe=recipe_dropdown)
                
    except ImportError:
        print("\n=== IPython í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤ ===")
        print("ìˆ˜ë™ìœ¼ë¡œ í•„í„°ë¥¼ ì„ íƒí•˜ì—¬ ì´ìƒì¹˜ë¥¼ ë¶„ì„í•˜ì„¸ìš”:")
        
        # ìˆ˜ë™ ì„ íƒ ì¸í„°í˜ì´ìŠ¤
        create_manual_anomaly_interface(df, equipment_ids, chamber_ids, recipes, analyze_filtered_anomalies)
        
    except Exception as e:
        print(f"ì¸í„°ë™í‹°ë¸Œ ìœ„ì ¯ ìƒì„± ì‹¤íŒ¨: {e}")
        print("ìˆ˜ë™ìœ¼ë¡œ í•„í„°ë¥¼ ì„ íƒí•˜ì—¬ ì´ìƒì¹˜ë¥¼ ë¶„ì„í•˜ì„¸ìš”:")
        
        # ìˆ˜ë™ ì„ íƒ ì¸í„°í˜ì´ìŠ¤
        create_manual_anomaly_interface(df, equipment_ids, chamber_ids, recipes, analyze_filtered_anomalies)

def create_manual_anomaly_interface(df, equipment_ids, chamber_ids, recipes, analyze_func):
    """ìˆ˜ë™ ì´ìƒì¹˜ ë¶„ì„ ì¸í„°í˜ì´ìŠ¤"""
    
    print("\n=== ì´ìƒì¹˜ ë¶„ì„ í•„í„° ì„ íƒ ===")
    print("ë¯¸ë¦¬ ì •ì˜ëœ ë¶„ì„ ì‹œë‚˜ë¦¬ì˜¤:")
    print("1. ëª¨ë“  ë°ì´í„°")
    print("2. Equipmentë³„ ë¶„ì„")
    print("3. Recipeë³„ ë¶„ì„")
    print("4. ì‚¬ìš©ì ì •ì˜ í•„í„°")
    print("5. ì£¼ìš” ì´ìƒì¹˜ íŒ¨í„´ ë¶„ì„")
    
    choice = input("ë¶„ì„ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš” (1-5) [ê¸°ë³¸ê°’: 1]: ").strip() or "1"
    
    if choice == "1":
        # ì „ì²´ ë°ì´í„° ë¶„ì„
        print("\n=== ì „ì²´ ë°ì´í„° ì´ìƒì¹˜ ë¶„ì„ ===")
        analyze_func('All', 'All', 'All')
        
    elif choice == "2":
        # Equipmentë³„ ë¶„ì„
        print("\n=== Equipmentë³„ ì´ìƒì¹˜ ë¶„ì„ ===")
        for eqp_id in equipment_ids[1:]:  # 'All' ì œì™¸
            print(f"\n--- Equipment: {eqp_id} ---")
            try:
                analyze_func(eqp_id, 'All', 'All')
            except Exception as e:
                print(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
                
    elif choice == "3":
        # Recipeë³„ ë¶„ì„
        print("\n=== Recipeë³„ ì´ìƒì¹˜ ë¶„ì„ ===")
        for recipe in recipes[1:]:  # 'All' ì œì™¸
            print(f"\n--- Recipe: {recipe} ---")
            try:
                analyze_func('All', 'All', recipe)
            except Exception as e:
                print(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
                
    elif choice == "4":
        # ì‚¬ìš©ì ì •ì˜ í•„í„°
        print("\n=== ì‚¬ìš©ì ì •ì˜ í•„í„° ===")
        
        while True:
            print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜:")
            print(f"Equipment: {', '.join(equipment_ids)}")
            print(f"Chamber: {', '.join(chamber_ids)}")
            print(f"Recipe: {', '.join(recipes)}")
            
            eqp_choice = input(f"Equipment ì„ íƒ [ê¸°ë³¸ê°’: All]: ").strip() or "All"
            if eqp_choice not in equipment_ids:
                print(f"âš ï¸ ì˜ëª»ëœ Equipment: {eqp_choice}")
                continue
                
            chamber_choice = input(f"Chamber ì„ íƒ [ê¸°ë³¸ê°’: All]: ").strip() or "All"
            if chamber_choice not in chamber_ids:
                print(f"âš ï¸ ì˜ëª»ëœ Chamber: {chamber_choice}")
                continue
                
            recipe_choice = input(f"Recipe ì„ íƒ [ê¸°ë³¸ê°’: All]: ").strip() or "All"
            if recipe_choice not in recipes:
                print(f"âš ï¸ ì˜ëª»ëœ Recipe: {recipe_choice}")
                continue
            
            print(f"\n=== ë¶„ì„: {eqp_choice}/{chamber_choice}/{recipe_choice} ===")
            try:
                analyze_func(eqp_choice, chamber_choice, recipe_choice)
            except Exception as e:
                print(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
            
            continue_choice = input("\në‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ë¶„ì„í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n) [ê¸°ë³¸ê°’: n]: ").strip().lower()
            if continue_choice != 'y':
                break
                
    elif choice == "5":
        # ì£¼ìš” ì´ìƒì¹˜ íŒ¨í„´ ë¶„ì„
        print("\n=== ì£¼ìš” ì´ìƒì¹˜ íŒ¨í„´ ë¶„ì„ ===")
        
        # ê°€ì¥ ë§ì€ ì´ìƒì¹˜ë¥¼ ê°€ì§„ ì¡°í•© ì°¾ê¸°
        temp_anomalies = df[df['TEMP'] > 450]
        
        if len(temp_anomalies) > 0:
            print("1. Equipmentë³„ ì´ìƒì¹˜ ë¶„í¬:")
            eqp_counts = temp_anomalies.groupby('eqp_id').size().sort_values(ascending=False)
            for eqp_id, count in eqp_counts.head(3).items():
                print(f"   {eqp_id}: {count}ê°œ")
                analyze_func(eqp_id, 'All', 'All')
            
            print("\n2. Recipeë³„ ì´ìƒì¹˜ ë¶„í¬:")
            recipe_counts = temp_anomalies.groupby('recipe').size().sort_values(ascending=False)
            for recipe, count in recipe_counts.head(3).items():
                print(f"   {recipe}: {count}ê°œ")
                analyze_func('All', 'All', recipe)
        else:
            print("ì´ìƒì¹˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ì „ì²´ ë°ì´í„° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        analyze_func('All', 'All', 'All')

def create_plotly_dashboard(csv_path='sample_manufacturing.csv'):
    """Plotly ê¸°ë°˜ ê°„ë‹¨í•œ ëŒ€ì‹œë³´ë“œ"""
    df = pd.read_csv(csv_path)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    # ê³ ìœ ê°’ë“¤ ì¶”ì¶œ
    equipment_ids = sorted(df['eqp_id'].unique().tolist())
    chamber_ids = sorted(df['chamber_id'].unique().tolist())
    recipes = sorted(df['recipe'].unique().tolist())
    
    print("=== Plotly ëŒ€ì‹œë³´ë“œ (ì •ì  ë²„ì „) ===")
    print("Equipment, Chamber, Recipeë³„ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤...")
    
    # Plotly ë Œë”ë§ ì„¤ì •
    import plotly.offline as pyo
    pyo.init_notebook_mode(connected=True)
    
    # ì „ì²´ ê°œìš”
    fig_overview = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Temperature Overview', 'RF Power Overview', 
                       'Equipment Distribution', 'Recipe Distribution'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"type": "pie"}, {"type": "pie"}]]
    )
    
    # ì˜¨ë„ ì „ì²´ ì‹œê³„ì—´
    fig_overview.add_trace(
        go.Scatter(x=df['timestamp'], y=df['TEMP'],
                  mode='lines', name='Temperature', line=dict(color='red', width=1)),
        row=1, col=1
    )
    
    # ì˜¨ë„ ì´ìƒì¹˜ í‘œì‹œ
    temp_anomalies = df[df['TEMP'] > 450]
    if len(temp_anomalies) > 0:
        fig_overview.add_trace(
            go.Scatter(x=temp_anomalies['timestamp'], y=temp_anomalies['TEMP'],
                      mode='markers', name='Temp Anomalies',
                      marker=dict(color='red', size=6, symbol='x')),
            row=1, col=1
        )
    
    # RF íŒŒì›Œ ì „ì²´ ì‹œê³„ì—´
    fig_overview.add_trace(
        go.Scatter(x=df['timestamp'], y=df['RF_POWER'],
                  mode='lines', name='RF Power', line=dict(color='green', width=1)),
        row=1, col=2
    )
    
    # RF íŒŒì›Œ ì´ìƒì¹˜ í‘œì‹œ
    power_anomalies = df[df['RF_POWER'] > 300]
    if len(power_anomalies) > 0:
        fig_overview.add_trace(
            go.Scatter(x=power_anomalies['timestamp'], y=power_anomalies['RF_POWER'],
                      mode='markers', name='Power Anomalies',
                      marker=dict(color='orange', size=6, symbol='triangle-up')),
            row=1, col=2
        )
    
    # Equipment ë¶„í¬
    eqp_counts = df.groupby('eqp_id').size()
    fig_overview.add_trace(
        go.Pie(labels=eqp_counts.index, values=eqp_counts.values, name="Equipment"),
        row=2, col=1
    )
    
    # Recipe ë¶„í¬
    recipe_counts = df.groupby('recipe').size()
    fig_overview.add_trace(
        go.Pie(labels=recipe_counts.index, values=recipe_counts.values, name="Recipe"),
        row=2, col=2
    )
    
    fig_overview.update_layout(height=800, title_text="Manufacturing Data Overview")
    
    # ê·¸ë˜í”„ í‘œì‹œ ì‹œë„
    try:
        print("1. ì „ì²´ ê°œìš” ëŒ€ì‹œë³´ë“œ í‘œì‹œ ì¤‘...")
        fig_overview.show()
    except Exception as e:
        print(f"ë¸Œë¼ìš°ì € í‘œì‹œ ì‹¤íŒ¨: {e}")
        # HTML íŒŒì¼ë¡œ ì €ì¥
        overview_path = "manufacturing_overview.html"
        fig_overview.write_html(overview_path)
        print(f"ëŒ€ì‹  HTML íŒŒì¼ë¡œ ì €ì¥ë¨: {overview_path}")
        print(f"ë¸Œë¼ìš°ì €ì—ì„œ íŒŒì¼ì„ ì—´ì–´ í™•ì¸í•˜ì„¸ìš”: file://{os.path.abspath(overview_path)}")
    
    # Equipmentë³„ ìƒì„¸ ë¶„ì„
    print("\n=== Equipmentë³„ ìƒì„¸ ë¶„ì„ ===")
    for eqp_id in equipment_ids:
        eqp_data = df[df['eqp_id'] == eqp_id]
        eqp_temp_anomalies = eqp_data[eqp_data['TEMP'] > 450]
        eqp_power_anomalies = eqp_data[eqp_data['RF_POWER'] > 300]
        
        print(f"\n{eqp_id}:")
        print(f"  ì´ ë°ì´í„°: {len(eqp_data):,}ê°œ")
        print(f"  ì˜¨ë„ ì´ìƒì¹˜: {len(eqp_temp_anomalies)}ê°œ ({len(eqp_temp_anomalies)/len(eqp_data):.2%})")
        print(f"  RF íŒŒì›Œ ì´ìƒì¹˜: {len(eqp_power_anomalies)}ê°œ ({len(eqp_power_anomalies)/len(eqp_data):.2%})")
        
        if len(eqp_temp_anomalies) > 3:  # ì´ìƒì¹˜ê°€ ë§ì€ ì¥ë¹„ë§Œ ì‹œê°í™”
            fig_eqp = make_subplots(
                rows=2, cols=1,
                subplot_titles=(f'{eqp_id} - Temperature', f'{eqp_id} - RF Power')
            )
            
            # ì˜¨ë„
            fig_eqp.add_trace(
                go.Scatter(x=eqp_data['timestamp'], y=eqp_data['TEMP'],
                          mode='lines', name='Temperature', line=dict(color='blue', width=1)),
                row=1, col=1
            )
            
            if len(eqp_temp_anomalies) > 0:
                fig_eqp.add_trace(
                    go.Scatter(x=eqp_temp_anomalies['timestamp'], y=eqp_temp_anomalies['TEMP'],
                              mode='markers', name='Temp Anomalies',
                              marker=dict(color='red', size=8, symbol='x')),
                    row=1, col=1
                )
            
            # RF íŒŒì›Œ
            fig_eqp.add_trace(
                go.Scatter(x=eqp_data['timestamp'], y=eqp_data['RF_POWER'],
                          mode='lines', name='RF Power', line=dict(color='green', width=1)),
                row=2, col=1
            )
            
            if len(eqp_power_anomalies) > 0:
                fig_eqp.add_trace(
                    go.Scatter(x=eqp_power_anomalies['timestamp'], y=eqp_power_anomalies['RF_POWER'],
                              mode='markers', name='Power Anomalies',
                              marker=dict(color='orange', size=8, symbol='triangle-up')),
                    row=2, col=1
                )
            
            fig_eqp.update_layout(height=600, title_text=f"Equipment {eqp_id} Analysis")
            
            try:
                print(f"   {eqp_id} ìƒì„¸ ë¶„ì„ ì°¨íŠ¸ í‘œì‹œ ì¤‘...")
                fig_eqp.show()
            except Exception as e:
                print(f"   ë¸Œë¼ìš°ì € í‘œì‹œ ì‹¤íŒ¨: {e}")
                # HTML íŒŒì¼ë¡œ ì €ì¥
                eqp_path = f"equipment_{eqp_id}_analysis.html"
                fig_eqp.write_html(eqp_path)
                print(f"   HTML íŒŒì¼ë¡œ ì €ì¥ë¨: {eqp_path}")
    
    # Recipeë³„ ë¹„êµ ë¶„ì„
    print("\n=== Recipeë³„ ë¹„êµ ë¶„ì„ ===")
    fig_recipe = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Temperature by Recipe', 'RF Power by Recipe',
                       'Anomaly Count by Recipe', 'Feature Correlation by Recipe')
    )
    
    colors = ['blue', 'green', 'purple', 'orange', 'red']
    
    # Recipeë³„ ì˜¨ë„ ë¶„í¬
    for i, recipe in enumerate(recipes):
        recipe_data = df[df['recipe'] == recipe]
        fig_recipe.add_trace(
            go.Box(y=recipe_data['TEMP'], name=f'{recipe} Temp', 
                  marker=dict(color=colors[i % len(colors)])),
            row=1, col=1
        )
    
    # Recipeë³„ RF íŒŒì›Œ ë¶„í¬
    for i, recipe in enumerate(recipes):
        recipe_data = df[df['recipe'] == recipe]
        fig_recipe.add_trace(
            go.Box(y=recipe_data['RF_POWER'], name=f'{recipe} Power',
                  marker=dict(color=colors[i % len(colors)])),
            row=1, col=2
        )
    
    # Recipeë³„ ì´ìƒì¹˜ ê°œìˆ˜
    recipe_anomaly_counts = []
    recipe_labels = []
    for recipe in recipes:
        recipe_data = df[df['recipe'] == recipe]
        anomaly_count = len(recipe_data[recipe_data['TEMP'] > 450])
        recipe_anomaly_counts.append(anomaly_count)
        recipe_labels.append(recipe)
    
    fig_recipe.add_trace(
        go.Bar(x=recipe_labels, y=recipe_anomaly_counts, name='Anomaly Count',
              marker=dict(color='red', opacity=0.7)),
        row=2, col=1
    )
    
    # ì „ì²´ íŠ¹ì„± ìƒê´€ê´€ê³„
    features = ['TEMP', 'PRESSURE', 'RF_POWER', 'CHAMBER_LOAD']
    corr_matrix = df[features].corr().values
    
    fig_recipe.add_trace(
        go.Heatmap(z=corr_matrix, x=features, y=features,
                  colorscale='RdBu', zmid=0, name='Correlation'),
        row=2, col=2
    )
    
    fig_recipe.update_layout(height=800, title_text="Recipe Comparison Analysis")
    
    try:
        print("2. Recipe ë¹„êµ ë¶„ì„ ì°¨íŠ¸ í‘œì‹œ ì¤‘...")
        fig_recipe.show()
    except Exception as e:
        print(f"ë¸Œë¼ìš°ì € í‘œì‹œ ì‹¤íŒ¨: {e}")
        # HTML íŒŒì¼ë¡œ ì €ì¥
        recipe_path = "recipe_comparison.html"
        fig_recipe.write_html(recipe_path)
        print(f"HTML íŒŒì¼ë¡œ ì €ì¥ë¨: {recipe_path}")
        print(f"ë¸Œë¼ìš°ì €ì—ì„œ íŒŒì¼ì„ ì—´ì–´ í™•ì¸í•˜ì„¸ìš”: file://{os.path.abspath(recipe_path)}")
    
    # ìš”ì•½ í†µê³„
    print(f"\n=== ì „ì²´ ìš”ì•½ í†µê³„ ===")
    print(f"ì´ ë°ì´í„° í¬ì¸íŠ¸: {len(df):,}ê°œ")
    print(f"Equipment ìˆ˜: {len(equipment_ids)}ê°œ")
    print(f"Chamber ìˆ˜: {len(chamber_ids)}ê°œ")
    print(f"Recipe ìˆ˜: {len(recipes)}ê°œ")
    print(f"ì˜¨ë„ ì´ìƒì¹˜: {len(temp_anomalies)}ê°œ ({len(temp_anomalies)/len(df):.2%})")
    
    power_anomalies = df[df['RF_POWER'] > 300]
    print(f"RF íŒŒì›Œ ì´ìƒì¹˜: {len(power_anomalies)}ê°œ ({len(power_anomalies)/len(df):.2%})")
    
    return df, temp_anomalies, power_anomalies

# ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
if __name__ == "__main__":
    print("=== ì œì¡°ì—… ë°ì´í„° ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ (ìºì‹œ ì§€ì›) ===")
    print("1. ê¸°ë³¸ ë¶„ì„ (ìºì‹œ ë¹„í™œì„±í™”)")
    print("2. ìºì‹œ í™œìš© ë¶„ì„ (ê¶Œì¥ - ë¹ ë¥¸ ì¬ì‹¤í–‰)")
    print("3. ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ (ìºì‹œ í™œìš©)")
    print("4. ì •ì  Plotly ëŒ€ì‹œë³´ë“œ")
    print("5. ìºì‹œ ì´ˆê¸°í™”")
    print("6. ì›¹ ëŒ€ì‹œë³´ë“œ ì‹¤í–‰")
    
    choice = input("ì„ íƒí•˜ì„¸ìš” (1/2/3/4/5/6) [ê¸°ë³¸ê°’: 2]: ").strip() or "2"
    
    if choice == "5":
        # ìºì‹œ ì´ˆê¸°í™”
        import shutil
        cache_dir = 'cache'
        if os.path.exists(cache_dir):
            shutil.rmtree(cache_dir)
            print("ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("ìºì‹œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        exit()
    
    elif choice == "6":
        # ì›¹ ëŒ€ì‹œë³´ë“œ ì‹¤í–‰
        try:
            import dash
            print(f"âœ… Dash ë²„ì „: {dash.__version__}")
            
            from web_dashboard import create_web_dashboard
            print("ì›¹ ëŒ€ì‹œë³´ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
            print("ë¸Œë¼ìš°ì €ì—ì„œ http://127.0.0.1:8050/ ìœ¼ë¡œ ì ‘ì†í•˜ì„¸ìš”.")
            print("ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")
            
            app = create_web_dashboard()
            app.run(debug=True, host='127.0.0.1', port=8050)
            
        except ImportError as e:
            print(f"âŒ í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
            print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
            print("pip install dash plotly pandas numpy")
        except FileNotFoundError:
            print("âŒ web_dashboard.py íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ì›¹ ëŒ€ì‹œë³´ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        exit()
    
    use_cache = choice in ["2", "3"]
    use_interactive = choice == "3"
    use_static = choice == "4"
    
    print(f"\nìºì‹œ ì‚¬ìš©: {'Yes' if use_cache else 'No'}")
    print(f"ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ: {'Yes' if use_interactive else 'No'}")
    print(f"ì •ì  ëŒ€ì‹œë³´ë“œ: {'Yes' if use_static else 'No'}")
    
    try:
        if use_static:
            # ì •ì  Plotly ëŒ€ì‹œë³´ë“œë§Œ ì‹¤í–‰
            print("ì •ì  Plotly ëŒ€ì‹œë³´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            create_plotly_dashboard('sample_manufacturing.csv')
        else:
            # ê¸°ì¡´ ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ ì‹¤í–‰
            model, scores, mask, threshold, df = detect_anomalies_with_model(
                'sample_manufacturing.csv', 
                use_interactive=use_interactive,
                use_cache=use_cache
            )
            
            # ì¶”ê°€ ë¶„ì„ ì •ë³´
            print(f"\n=== ì¶”ê°€ ë¶„ì„ ê²°ê³¼ ===")
            anomaly_indices = np.where(mask)[0]
            print(f"ì´ìƒìœ¼ë¡œ íƒì§€ëœ ì‹œì ë“¤ (ì²˜ìŒ 10ê°œ):")
            for idx in anomaly_indices[:10]:
                print(f"  Index {idx}: Score {scores[idx]:.6f}")
            
            # ì‹¤ì œ ì´ìƒì¹˜ì™€ ë¹„êµ
            temp_anomalies = df[df['TEMP'] > 450]
            power_anomalies = df[df['RF_POWER'] > 300]
            
            print(f"\nì‹¤ì œ ë°ì´í„° ì´ìƒì¹˜:")
            print(f"  ì˜¨ë„ ì´ìƒì¹˜ (>450Â°C): {len(temp_anomalies)}ê°œ")
            print(f"  RF íŒŒì›Œ ì´ìƒì¹˜ (>300): {len(power_anomalies)}ê°œ")
            print(f"  ëª¨ë¸ íƒì§€ ì´ìƒì¹˜: {len(anomaly_indices)}ê°œ")
            
            # ì¥ë¹„/ì±”ë²„/ë ˆì‹œí”¼ë³„ ì´ìƒì¹˜ ë¶„ì„
            analyze_anomalies_by_groups(df, temp_anomalies, power_anomalies, scores, mask)
            
            # ìƒê´€ê´€ê³„ ë¶„ì„
            if len(temp_anomalies) > 0:
                print(f"\nì˜¨ë„ ì´ìƒì¹˜ ìƒì„¸ (ì²˜ìŒ 5ê°œ):")
                for idx, row in temp_anomalies.head().iterrows():
                    print(f"  {row['timestamp']}: TEMP={row['TEMP']:.2f}Â°C, RF_POWER={row['RF_POWER']:.2f}, Recipe={row['recipe']}")
            
            # ì¸í„°ë™í‹°ë¸Œ ì´ìƒì¹˜ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
            if use_interactive:
                print(f"\n=== ì¸í„°ë™í‹°ë¸Œ ì´ìƒì¹˜ ë¶„ì„ ì‹œì‘ ===")
                create_anomaly_analysis_dashboard(df, scores, mask, threshold)
        
    except Exception as e:
        print(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        print("ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤...")
        try:
            model, scores, mask, threshold, df = detect_anomalies_with_model(
                'sample_manufacturing.csv', use_interactive=False, use_cache=False
            )
        except Exception as inner_e:
            print(f"ê¸°ë³¸ ëª¨ë“œ ì‹¤í–‰ë„ ì‹¤íŒ¨: {inner_e}")
            exit(1)
    
    # ìºì‹œ ìƒíƒœ í™•ì¸
    if use_cache:
        cache_dir = 'cache'
        if os.path.exists(cache_dir):
            cache_files = os.listdir(cache_dir)
            print(f"\n=== ìºì‹œ ìƒíƒœ ===")
            print(f"ìºì‹œ ë””ë ‰í† ë¦¬: {cache_dir}")
            print(f"ìºì‹œ íŒŒì¼ë“¤: {cache_files}")
            
            # ìºì‹œ í¬ê¸° í™•ì¸
            total_size = 0
            for file in cache_files:
                file_path = os.path.join(cache_dir, file)
                if os.path.isfile(file_path):
                    total_size += os.path.getsize(file_path)
            print(f"ìºì‹œ ì´ í¬ê¸°: {total_size / (1024*1024):.2f} MB")
    
    print(f"\në¶„ì„ ì™„ë£Œ! ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")
    if use_cache:
        print("ë‹¤ìŒ ì‹¤í–‰ ì‹œì—ëŠ” ìºì‹œëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë” ë¹ ë¥´ê²Œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    
    # ì¶”ê°€ ì˜µì…˜ ì œê³µ
    print(f"\n=== ì¶”ê°€ ì˜µì…˜ ===")
    print("ë‹¤ë¥¸ ë¶„ì„ì„ ì›í•˜ì‹œë©´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
    if not use_interactive:
        print("ì¸í„°ë™í‹°ë¸Œ ë¶„ì„ì„ ì›í•˜ì‹œë©´ ì˜µì…˜ 3ì„ ì„ íƒí•˜ì„¸ìš”.")
    if not use_static:
        print("ì •ì  ëŒ€ì‹œë³´ë“œë¥¼ ì›í•˜ì‹œë©´ ì˜µì…˜ 4ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
    print("ì›¹ ëŒ€ì‹œë³´ë“œë¥¼ ì›í•˜ì‹œë©´ ì˜µì…˜ 6ì„ ì„ íƒí•˜ì„¸ìš”.")
